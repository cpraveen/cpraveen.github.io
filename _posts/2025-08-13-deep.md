---
title: Talk by Deep Ray, Univ. of Maryland
layout: post
---

**Title:**  Can we learn the optimal PDE solution?  
**Speaker:**  Deep Ray [Department of Mathematics, Institute for Physical Science and Technology University of Maryland]  
**Date and Time:** August 19th, 2025 [Tuesday] **at 04:30 pm**  
**Venue:** Online mode (Zoom meeting details below)

**Abstract:**  Operator networks have recently emerged as powerful surrogate solvers for PDEs, enabling fast evaluations in many-query applications. However, most do not respect the variational formulation that underpins classical PDE solvers. In this talk, we introduce a novel operator network framework called PG-VarMiON which emulates the PDE’s optimal Petrov-Galerkin formulation, where we seek the orthogonal projection of the infinite-dimensional weak solution onto a given finite-dimensional trial space with respect to a chosen norm. The optimal Petrov-Galerkin approach can overcome practical challenges faced by standard Galerkin approaches. However, recovery of the optimal solution is contingent on being able to construct the optimal weighting functions associated with the trial basis. While explicit constructions are available for simple problems, such constructions for a general multidimensional problem remain elusive. The proposed PG-VarMiON can approximate the optimal solution while implicitly learning the optimal weighting functions. Several numerical results for the advection-diffusion equation are presented to demonstrate the efficacy of the proposed method. By embedding the Petrov-Galerkin structure into the network architecture, PG-VarMiON exhibits greater robustness and improved generalization compared to other deep operator frameworks, particularly when training data is limited. The proposed approach harnesses the knowledge of classical numerical methods to design efficient deep surrogates.

**Speaker Bio:**  Deep Ray is a faculty member at the University of Maryland, USA, with joint appointments in the Department of Mathematics and the Institute for Physical Science and Technology. He earned his Ph.D. in Mathematics from the TIFR Centre for Applicable Mathematics, Bangalore. He has worked at EPFL, Switzerland; Rice University, USA; and the University of Southern California, USA. His research focuses on numerical analysis and scientific machine learning, including shock-capturing algorithms, reduced-order modelling, acceleration of Monte Carlo methods, PDE-constrained optimization, Bayesian inference, and entropy-stable schemes for conservation laws.

**Join Zoom Meeting**
https://zoom.us/j/98029012618?pwd=VoNJQPbwif5bvp32bjqNI0ffRtO7WU.1

<p style="text-align:center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/m6TNLsTfZVg?si=VneqFlkSxzeVpEzm" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</p>
